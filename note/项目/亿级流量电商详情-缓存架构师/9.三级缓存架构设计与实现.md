## 一、商品详情页结构拆分

我们项目缓存的技术方案分为两块：

第一块，是做实时性比较高的那块数据，比如说库存，销量之类的这种数据，我们采取的实时缓存+数据库双写的技术方案，双写一致性保障的方案

第二块，是做实时性要求不高的数据，比如商品的基本信息等，我们采取的是三级缓存架构的技术方案，就是说由一个专门的数据生产服务，去获取整个商品详情页需要的各种数据，经过处理后，将数据放入各级缓存中，每一级缓存都有自己的作用。

**1、大型电商网站中的商品详情页的数据结构分析**

商品的基本信息

标题：【限时直降】Apple/苹果 iPhone 7 128G 全网通4G智能手机正品
短描述：限时优惠 原封国行 正品保障
颜色：
存储容量
图片列表
规格参数

其他信息：店铺信息，分类信息，等等，非商品维度的信息

商品介绍：放缓存，看一点，ajax异步从缓存加载一点，不放我们这里讲解

实时信息：实时广告推荐、实时价格、实时活动推送，等等，ajax加载

将商品的各种基本信息，分类放到缓存中，每次请求过来，动态从缓存中取数据，然后动态渲染到模板中

数据放缓存，性能高，动态渲染模板，灵活性好

**2、大型缓存全量更新的问题**

当我们把商品相关的信息维护一条json放到缓存中时，会出现以下问题：

（1）网络耗费的资源大
（2）每次对redis都存取大数据，对redis的压力也比较大
（3）redis的性能和吞吐量能够支撑到多大，基本跟数据本身的大小有很大的关系，如果数据越大，那么可能导致redis的吞吐量就会急剧下降

**3、缓存维度化解决方案**

维度化也就是将商品信息进行拆分，拆分维度包括：商品维度、商品分类维度、商品店铺维度，不同的维度，可以看做是不同的角度去观察一个东西，那么每个商品详情页中，都包含了不同的维度数据。

如果不维度化，就会导致多个维度的数据混合在一个缓存value中，但是不同维度的数据可能更新频率都不大一样，

唯独化：将每个维度的数据都存一份，比如说商品维度的数据存一份，商品分类的数据存一份，商品店铺的数据存一份

那么在不同的维度数据更新的时候，只要去更新对应的维度就可以了

包括我们之前讲解的那种实时性较高的数据，也可以理解为一个维度。

## 二、kafka实现商品消费队列

![](F:\__study__\hulianwang\study\note\项目\亿级流量电商详情-缓存架构师\img\多级缓存架构.png)

商品信息管理服务是单独的一个服务，如果商品信息有变更之后，会将变更后的数据放入kafka中，然后缓存数据生产服务获取到消息后，更新ehcache与redis中的数据。

**1、商品详情页缓存数据生产服务的工作流程分析**

（1）监听多个kafka topic，每个kafka topic对应一个服务（简化一下，监听一个kafka topic），商品信息管理服务可能也是分布式部署的存在多个节点，每个kafka topic对应一个java应用节点。  
（2）如果一个服务发生了数据变更，那么就发送一个消息到kafka topic中  
（3）缓存数据生产服务监听到了消息以后，就发送请求到对应的服务中调用接口以及拉取数据，此时是从mysql中查询的  
（4）缓存数据生产服务拉取到了数据之后，会将数据在本地缓存中写入一份，就是ehcache中  
（5）同时会将数据在redis中写入一份

**2、ehcache本地缓存服务层开发**

三级缓存，多级缓存，服务本地堆缓存+redis分布式缓存+nginx本地缓存组成的。

每一层缓存在高并发的场景下，都有其特殊的用途，需要综合利用多级的缓存，才能支撑高并发场景下各种各样的特殊情况

服务本地堆缓存，作用：预防redis层的彻底崩溃，作为缓存的最后一道防线，避免数据库直接裸奔。

**3、关于缓存中的LRU算法**

数据写入redis分布式缓存中一份，你不断的将数据写入redis，然后redis的内存是有限的，每个redis实例最大一般也就是设置给10G那如果你不断的写入数据，当数据写入的量超过了redis能承受的范围之后，就会将数据进行一定的清理，从内存中清理掉一些数据，只有清理掉一些数据之后，才能将新的数据写入内存中

1、LRU算法概述

redis默认情况下就是使用LRU策略的，因为内存是有限的，但是如果你不断地往redis里面写入数据，那肯定是没法存放下所有的数据在内存的

所以redis默认情况下，当内存中写入的数据很满之后，就会使用LRU算法清理掉部分内存中的数据，腾出一些空间来，然后让新的数据写入redis缓存中

LRU：Least Recently Used，最近最少使用算法

将最近一段时间内，最少使用的一些数据，给干掉。比如说有一个key，在最近1个小时内，只被访问了一次; 还有一个key在最近1个小时内，被访问了1万次

这个时候比如你要将部分数据给清理掉，你会选择清理哪些数据啊？肯定是那个在最近小时内被访问了1万次的数据

2、缓存清理设置

redis.conf

maxmemory，设置redis用来存放数据的最大的内存大小，一旦超出这个内存大小之后，就会立即使用LRU算法清理掉部分数据

如果用LRU，那么就是将最近最少使用的数据从缓存中清除出去

对于64 bit的机器，如果maxmemory设置为0，那么就默认不限制内存的使用，直到耗尽机器中所有的内存为止; 但是对于32 bit的机器，有一个隐式的闲置就是3GB

maxmemory-policy，可以设置内存达到最大闲置后，采取什么策略来处理

（1）noeviction: 如果内存使用达到了maxmemory，client还要继续写入数据，那么就直接报错给客户端
（2）allkeys-lru: 就是我们常说的LRU算法，移除掉最近最少使用的那些keys对应的数据（最常）
（3）volatile-lru: 也是采取LRU算法，但是仅仅针对那些设置了指定存活时间（TTL）的key才会清理掉
（4）allkeys-random: 随机选择一些key来删除掉
（5）volatile-random: 随机选择一些设置了TTL的key来删除掉
（6）volatile-ttl: 移除掉部分keys，选择那些TTL时间比较短的keys

3、缓存清理的流程

（1）客户端执行数据写入操作
（2）redis server接收到写入操作之后，检查maxmemory的限制，如果超过了限制，那么就根据对应的policy清理掉部分数据
（3）写入操作完成执行

4、redis的LRU近似算法

科普一个相对来说稍微高级一丢丢的知识点

redis采取的是LRU近似算法，也就是对keys进行采样，然后在采样结果中进行数据清理

redis 3.0开始，在LRU近似算法中引入了pool机制，表现可以跟真正的LRU算法相当，但是还是有所差距的，不过这样可以减少内存的消耗

redis LRU算法，是采样之后再做LRU清理的，跟真正的、传统、全量的LRU算法是不太一样的

maxmemory-samples，比如5，可以设置采样的大小，如果设置为10，那么效果会更好，不过也会耗费更多的CPU资源

